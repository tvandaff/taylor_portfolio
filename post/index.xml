<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects on Taylor Sullivan</title>
    <link>https://tvandaff.github.io/taylor_portfolio/post/</link>
    <description>Recent content in Projects on Taylor Sullivan</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Mon, 02 Mar 2020 12:00:00 -0500</lastBuildDate>
    
	<atom:link href="https://tvandaff.github.io/taylor_portfolio/post/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Project 1: Feature Engineering on the Cloud</title>
      <link>https://tvandaff.github.io/taylor_portfolio/post/project-1/</link>
      <pubDate>Mon, 01 December 2021 10:58:08 -0400</pubDate>
      
      <guid>https://tvandaff.github.io/taylor_portfolio/post/project-1/</guid>
      <description>In this project, I harness Google AI APIs and cloud resources to deploy an end-to-end taxi fare prediction application capable of receivinf sound bytes, text, location information, and images to create accurate fare predictions for the NYC area.</description>
    </item>
    
    <item>
      <title>Project 2: TELCO Analysis in Python</title>
      <link>https://tvandaff.github.io/taylor_portfolio/post/project-2/</link>
      <pubDate>Thu, 01 Aug 2019 11:00:59 -0400</pubDate>
      
      <guid>https://tvandaff.github.io/taylor_portfolio/post/project-2/</guid>
      <description>This project conducts an analysis of customer characteristics to determine which are the best predictors for tenure. Out of the many services the company offered, customers were most likely to continue utilizing TELCO services if they were enrolled in a phone or internet service.
In this project I use univariate analysis to analyze the frequency counts of internet service and automatic payment methods. I then utilize bivariate analysis to conduct covariance analysis prior to building a model.</description>
    </item>
    
    <item>
      <title>Project 3: Fairness</title>
      <link>https://tvandaff.github.io/taylor_portfolio/post/project-3/</link>
      <pubDate>Fri, 01 Apr 2022 11:13:32 -0400</pubDate>
      
      <guid>https://tvandaff.github.io/taylor_portfolio/post/project-3/</guid>
      <description>For this project, I systematically identify fairness issues in AI-enabled systems and think through potential fairness problems in a credit scoring scenario and in a movie streaming scenario. Specifically, I (1) identified potential harms that can be caused by an unfair AI system, (2) identified potential sources of bias, (3) analyzed and improved fairness of a classifier, and (4) discussed possible fairness practices throughout the system&#39;s life cycle.</description>
    </item>
    
    <item>
      <title>Project 4: Census Predictions in R</title>
      <link>https://tvandaff.github.io/taylor_portfolio/post/project-4/</link>
      <pubDate>Fri, 01 Feb 2019 11:14:48 -0400</pubDate>
      
      <guid>https://tvandaff.github.io/taylor_portfolio/post/project-4/</guid>
      <description>Linear Regression Model of Texas Census Data   First, I conducted a linear regression analysis for use in predicting the size of the population for the state selected, based on the Current Estimates Data dataset. I used tidyverse and dplyr packages to complete the project.
I then cleaned the data	by removing the column names in the Texas dataframe with names(estimates) &amp;lt;- NULL function and then built a vector with the as.</description>
    </item>
    
    <item>
      <title>Project 5: 911 Emergency Analysis in Python</title>
      <link>https://tvandaff.github.io/taylor_portfolio/post/project-5/</link>
      <pubDate>Tue, 01 Jan 2019 11:15:58 -0400</pubDate>
      
      <guid>https://tvandaff.github.io/taylor_portfolio/post/project-5/</guid>
      <description>In this project, I analyzed the data with univariate analysis to determine that the dataset necessitated the following corrections:
 From initial inspection, some features carry redundant information: Longitude, Latitude, Incident Location, Hundred Block Location; District/Sector and Zone/Beat Additionally, At Scene Time is missing many values For consistency&amp;rsquo;s sake, the OFFICERS_AT_SCENE feature should be altered in style to match the others Zone/Beats, Incident Type Group, Incident Type Subgroup, District/Sector, Event Clearance Group, Event Clearance Subgroup, Event Clearance Code should be changed into categories instead of a Strings/int64 CAD CDW ID, CAD Event Number, General Offense Number should be changed to strings instead of int64 The Census Tract feature max and 75% numbers seem extrordinarily high Remove NaN census observation  I then proceeded to clean the data:</description>
    </item>
    <item>
      <title>Project 6: Persona-lize</title>
      <link>https://tvandaff.github.io/taylor_portfolio/post/project-6/</link>
      <pubDate>Tue, 10 May 2022 11:15:58 -0400</pubDate>
      <guid>https://tvandaff.github.io/taylor_portfolio/post/project-6/</guid>
      <description>The Persona-Based Trip Planning App: A User Experience Project</description>
    </item>
  </channel>
</rss>